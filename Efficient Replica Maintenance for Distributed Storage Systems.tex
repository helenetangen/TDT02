\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{color}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{caption}


\begin{document}

\section*{Efficient Replica Maintenance for Distributed Storage Systems}

The area of focus of the Carbonite algorithm is durably and cost-efficiently storing of immutable object in a system that aggregates the disks of many Internet nodes. Hence, Carbonite is a replication algorithm for large storage systems. \textcolor{red}{More.}\\

\noindent To ensure availability (immediate access to data) of data, replication systems responds to disk failure by creating new replicas. When availability is key, replication is immediately used regardless if the failure was a disk failure or just a transient (temporary) failure. The problem of this approach is that constantly making new replicas is costly, and do not scale to large systems. The developers of Carbonite realized that Internet users can tolerate some unavailability as long as they eventually will be able to view what they requested. This knowledge is the main motivation behind Carbonite. With main focus on durability, not availability, they could build an Internet scale replication system. \textcolor{red}{Need to talk about reintegration and replication faster than failure, but I don't know if it should be done here or in the technique-paragraph.}\\

\noindent As mentioned above, being able to large storage application systems require sophisticated techniques for when and how replication is performed.

Only create new when below target number. 

One of the main techniques used in the paper is re-integration of failed nodes when they come back up again. By remembering which replicas was stored on a node, they can be reused, and thereby 


\end{document}